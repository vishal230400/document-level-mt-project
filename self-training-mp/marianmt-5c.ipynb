{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    # Freezing all but the last two decoder blocks for fine tuning\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"model.decoder.layers.4\") or name.startswith(\"model.decoder.layers.5\"):\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_training(model, source_doc, target_doc, tokenizer, lr=5e-3, decay_lambda=0.7, hybrid_alpha=0.4, num_steps=2, passes=2):\n",
    "    model.train()\n",
    "    # optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    # Store original parameters for decay regularization\n",
    "    og_params = [p.detach().clone() for p in model.parameters()]\n",
    "\n",
    "    for pass_idx in range(passes):\n",
    "        for sent_idx, (en_sent, hi_sent) in enumerate(zip(source_doc, target_doc)):\n",
    "            \n",
    "            source_tokens = tokenizer(\n",
    "                en_sent, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=True, \n",
    "                truncation=True\n",
    "                # max_length=512\n",
    "            ).to(model.device)\n",
    "\n",
    "            # Generate translation\n",
    "            with torch.no_grad():\n",
    "                # generated_tokens = model.generate(**source_tokens, max_length=128)\n",
    "                generated_tokens = model.generate(**source_tokens)\n",
    "            pseudo_translations = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "            # Tokenize generated translation as target\n",
    "            pseudo_targets = tokenizer(text_target=pseudo_translations, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "            gold_targets = tokenizer(text_target=[hi_sent], return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "            for step in range(num_steps):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pseudo_loss = model(**source_tokens, labels=pseudo_targets[\"input_ids\"]).loss\n",
    "                gold_loss = model(**source_tokens, labels=gold_targets[\"input_ids\"]).loss    \n",
    "                total_loss = hybrid_alpha*pseudo_loss + (1-hybrid_alpha)*gold_loss\n",
    "\n",
    "                total_loss.backward()\n",
    "\n",
    "                # Optional: gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                # Decay regularization\n",
    "                for p_current, p_orig in zip(model.parameters(), og_params):\n",
    "                    if p_current.grad is not None:\n",
    "                        p_current.grad += decay_lambda * (p_current - p_orig)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                # print(f\"[Pass {pass_idx} | Sentence {sent_idx} | Step {step}] Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from the .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1277\n",
      "1277\n",
      "450\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "with open('../output_with_train_split.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "en_train = []\n",
    "hi_train = []\n",
    "en_test = []\n",
    "hi_test = []\n",
    "hi_test_names = []\n",
    "\n",
    "for document in data:\n",
    "    en_doc = [sent['english'] for sent in document['sentences']]\n",
    "    hi_doc = [sent['hindi'] for sent in document['sentences']]\n",
    "    \n",
    "    if document['is_train']:\n",
    "        en_train.append(en_doc)\n",
    "        hi_train.append(hi_doc)\n",
    "    else:\n",
    "        en_test.append(en_doc)\n",
    "        hi_test.append(hi_doc)\n",
    "        hi_test_names.append(document['doc_name'].replace('.txt',''))\n",
    "    \n",
    "print(len(en_train))\n",
    "print(len(hi_train))\n",
    "print(len(en_test))\n",
    "print(len(hi_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translations(model, tokenizer, sentences, title=\"\"):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "        outputs = model.generate(**inputs, max_length=128)\n",
    "        translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        for en, hi in zip(sentences, translations):\n",
    "            print(f\"EN: {en}\")\n",
    "            print(f\"HI: {hi}\")\n",
    "            print()\n",
    "\n",
    "def write_translations(model, tokenizer, sentences, docName=\"\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "        outputs = model.generate(**inputs)\n",
    "        translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        with open(f\"5c/translations_{docName}.txt\", \"w\") as f:\n",
    "            for hi in translations:\n",
    "                f.write(f\"{hi}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pm(dir_path, num_docs=250, seed=42):\n",
    "    random.seed(seed)\n",
    "    all_docs = [f for f in os.listdir(dir_path) if f.endswith(\".txt\")]\n",
    "\n",
    "    selected_docs = random.sample(all_docs, k=num_docs)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for filename in selected_docs:\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        with open(file_path, \"r\", encoding='utf-8') as fin:\n",
    "            sentences = [line.strip() for line in fin.readlines() if line.strip()]\n",
    "            if sentences:\n",
    "                documents.append(sentences)\n",
    "    return documents\n",
    "\n",
    "dir_path = \"../../dataset/split\"\n",
    "source_docs = load_from_pm(dir_path, num_docs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc 1: Before Self-Training ---\n",
      "EN: The Prime Minister, Shri Narendra Modi will be on a visit to his Parliamentary Constituency, Varanasi, on September 17 and 18, 2018.\n",
      "HI: प्रधानमंत्री, शैरी नाही मोडी, सितंबर 17 और 1818 के सितंबर में अपने कॉन्वेंटीसी के लिए एक भेंट पर होगा ।\n",
      "\n",
      "EN: He will arrive in the city on the afternoon of 17th September.\n",
      "HI: वह 17 सितंबर की दोपहर को शहर आएगा ।\n",
      "\n",
      "EN: He will head directly for Narur village, where he will interact with children of a primary school who are being aided by the non-profit organisation “Room to Read.”\n",
      "HI: वह सीधे मोकर गाँव का मुखिया होगा, जहाँ वो एक प्राथमिक स्कूल के बच्चों के साथ व्यवहार करेगा जो गैर-कानूनी संगठन द्वारा मदद की जा रही हैं \" पढ़ें\"।\n",
      "\n",
      "EN: Later, at DLW campus, the Prime Minister will interact with students of Kashi Vidyapeeth, and children assisted by them.\n",
      "HI: बाद में, DLWWA में, प्रधानमंत्री कोशीशी विटस्‌ के विद्यार्थियों के साथ व्यवहार करेंगे, और बच्चों ने उनकी सहायता की ।\n",
      "\n",
      "EN: On the 18th, at BHU Amphitheatre, the Prime Minister will inaugurate or lay the Foundation Stone for various development projects, cumulatively worth more than Rs. 500 crore.\n",
      "HI: सन्‌ 18वीं सदी में, BHU Ancute में प्रधानमंत्री को कई विकास परियोजनाओं के लिए आधार बनाने या नींव डालने के लिए कहा जाता है ।\n",
      "\n",
      "EN: Among the projects to be inaugurated are: Integrated Power Development Scheme (IPDS) for Puraani Kashi; and an Atal Incubation Centre at BHU.\n",
      "HI: उद्‌घाटन के लिए परियोजनाओं में से कुछ हैं: मैं निर्माण विकास योजना (IPPS) suU में AHU में एक प्रवेश केंद्र के लिए (IPSS); और एक प्रवेश - केंद्र में।\n",
      "\n",
      "EN: Among the projects for which the Foundation Stone will be laid, is the Regional Ophthalmology Centre at BHU.\n",
      "HI: इन परियोजनाओं में से एक है जिसके लिए आधार पत्थर रखा जाएगा, BHU में क्षेत्रीय ओपिकल केंद्र ।\n",
      "\n",
      "EN: The Prime Minister will also address the gathering.\n",
      "HI: प्रधानमंत्री को पार्टी का भी पता चलेगा.\n",
      "\n",
      "\n",
      "--- Doc 2: Before Self-Training ---\n",
      "EN: The Prime Minister, Shri Narendra Modi, will launch the Stand Up India initiative at Noida tomorrow.\n",
      "HI: प्रधानमंत्री, शैरी नोरा मोडी, कल नोडा में खड़े भारत की पहल शुरू कर देगा.\n",
      "\n",
      "EN: The initiative will promote entrepreneurship among the Scheduled Castes, Scheduled Tribes, and Women, by facilitating loans in the range of Rs. 10 Lakhs to Rs. 100 Lakhs.\n",
      "HI: 10 लाखियाँ आर. 10 L. 100 Lhs. 100 L. 100 L.L. 100 L.L. 100 L. 100 L.\n",
      "\n",
      "EN: Each branch of a scheduled commercial bank shall facilitate at least two such loans.\n",
      "HI: एक तय बैंक के हर शाखा को ऐसे दो उधारों को कम - से - कम दो कर देना चाहिए ।\n",
      "\n",
      "EN: A web portal will also be launched for the initiative, to enable online registration and support services.\n",
      "HI: एक वेब पोर्टल पहल के लिए भी चालू किया जाएगा, ऑनलाइन पंजीकरण तथा समर्थन सेवाओं को समर्थ करने के लिए.\n",
      "\n",
      "EN: The Prime Minister will flag-off 5100 e-rickshaws on the occasion.\n",
      "HI: प्राइम मंत्री 5100 ई-रिकिंग को उस अवसर पर झंडा होगा.\n",
      "\n",
      "EN: He will interact with the beneficiaries, besides inaugurating a Kaushal Vikas Kendra (Skilling Centre).\n",
      "HI: उन्होंने कहा कि Tafowayposs के साथ बातचीत करेंगे, इसके अलावा एक Kuwachous केन केन्रा (सिंग केंद्र) के अलावा,।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(en_test[:2]):\n",
    "    print_translations(model, tokenizer, doc, title=f\"Doc {idx+1}: Before Self-Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Training Loop with Hybrid Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Training...: 1277it [9:22:56, 26.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# num_docs = len(en_train)\n",
    "for src_doc, tar_doc in tqdm(zip(en_train, hi_train), desc='Self Training...'):\n",
    "    model = self_training(\n",
    "        model=model,\n",
    "        source_doc=src_doc,\n",
    "        target_doc=tar_doc,\n",
    "        tokenizer=tokenizer,\n",
    "        lr=1e-4,\n",
    "        decay_lambda=0.9,\n",
    "        hybrid_alpha=0.25,\n",
    "        num_steps=2,\n",
    "        passes=3\n",
    "    )\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "torch.save(model.state_dict(), \"./5c.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc 1: After Self-Training ---\n",
      "EN: The Prime Minister, Shri Narendra Modi will be on a visit to his Parliamentary Constituency, Varanasi, on September 17 and 18, 2018.\n",
      "HI: प्रधानमंत्री नरेन्‍न्‍द्र मोदी ने 17 और 1818 के सितंबर को अपनी सरकार से मिलने के लिए कहा ।\n",
      "\n",
      "EN: He will arrive in the city on the afternoon of 17th September.\n",
      "HI: वह 17 सितंबर की दोपहर को शहर आएगा ।\n",
      "\n",
      "EN: He will head directly for Narur village, where he will interact with children of a primary school who are being aided by the non-profit organisation “Room to Read.”\n",
      "HI: वह सीधे मोयर गांव के लिए सिर होगा, जहां एक प्राथमिक स्कूल के बच्चों के साथ बातचीत की जा रही है जो गैर-कानूनी संगठन द्वारा मदद की जा रही है \" पढ़ें\"।\n",
      "\n",
      "EN: Later, at DLW campus, the Prime Minister will interact with students of Kashi Vidyapeeth, and children assisted by them.\n",
      "HI: बाद में, DLWWA में प्रधानमंत्री ने नीशी वदवस्‍त के विद्यार्थियों के साथ व्यवहार किया, और बच्चों ने उनकी सहायता की ।\n",
      "\n",
      "EN: On the 18th, at BHU Amphitheatre, the Prime Minister will inaugurate or lay the Foundation Stone for various development projects, cumulatively worth more than Rs. 500 crore.\n",
      "HI: अठारहवे पर, ब्‍न्‍री में प्रधानमंत्री स्‍ले में या विभिन्‍न विकास परियोजनाओं के लिए आधार रखता है, और स्‍वस्‍त रूप से स्‍वस्‍त्य रूप से अधिक मूल्य का आधार होता है।\n",
      "\n",
      "EN: Among the projects to be inaugurated are: Integrated Power Development Scheme (IPDS) for Puraani Kashi; and an Atal Incubation Centre at BHU.\n",
      "HI: उद्‌घाटन के लिए परियोजनाओं में से एक हैं: मैं ऊर्जा विकास योजना (IPFS) कांन्‍नी कात्‍न्‍नी कात्‍न्‍न; और बHU में एक प्रवेश केंद्र के लिए।\n",
      "\n",
      "EN: Among the projects for which the Foundation Stone will be laid, is the Regional Ophthalmology Centre at BHU.\n",
      "HI: इन परियोजनाओं में से एक है जिसके लिए आधार पत्थर रखा जाएगा, BHU में क्षेत्रीय ऑस्‍स्‍स्‍स्‍स्‍स्‍यश्‍दी केंद्र।\n",
      "\n",
      "EN: The Prime Minister will also address the gathering.\n",
      "HI: प्रधानमंत्री मंत्री भी एकत्र होगा।\n",
      "\n",
      "\n",
      "--- Doc 2: After Self-Training ---\n",
      "EN: The Prime Minister, Shri Narendra Modi, will launch the Stand Up India initiative at Noida tomorrow.\n",
      "HI: प्रधानमंत्री नीन्‍द्र मोदी मोदी ने नीदी कल में भारत के पद पर निगरानी रखी।\n",
      "\n",
      "EN: The initiative will promote entrepreneurship among the Scheduled Castes, Scheduled Tribes, and Women, by facilitating loans in the range of Rs. 10 Lakhs to Rs. 100 Lakhs.\n",
      "HI: 10 लांख की सीमा में रीफ्‍त के रूप में उधार लेने के द्वारा ।\n",
      "\n",
      "EN: Each branch of a scheduled commercial bank shall facilitate at least two such loans.\n",
      "HI: एक संक्षिप्त बैंक के हर शाखा को कम से कम दो ऐसे ऋणों को उधार देना पड़ेगा।\n",
      "\n",
      "EN: A web portal will also be launched for the initiative, to enable online registration and support services.\n",
      "HI: एक वेब पोर्टल पहल के लिए भी चालू किया जाएगा, ऑनलाइन पंजीकरण तथा समर्थन सेवाएँ सक्षम करने के लिए.\n",
      "\n",
      "EN: The Prime Minister will flag-off 5100 e-rickshaws on the occasion.\n",
      "HI: प्रधानमंत्री मंत्री 5100 ई-स्वस्‍तव को उस अवसर पर झंडे का पालन करेगा।\n",
      "\n",
      "EN: He will interact with the beneficiaries, besides inaugurating a Kaushal Vikas Kendra (Skilling Centre).\n",
      "HI: उन्होंने कहा कि नरेफ्‍द्रियों के साथ व्यवहार करेंगे, एक नललवल केनन्‍द्र्रा (स्‍लस्‍तिंग केंद्र) के अलावा।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(en_test[:2]):\n",
    "    print_translations(model, tokenizer, doc, title=f\"Doc {idx+1}: After Self-Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc 1: After Self-Training ---\n",
      "EN: The Prime Minister, Shri Narendra Modi will be on a visit to his Parliamentary Constituency, Varanasi, on September 17 and 18, 2018.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: He will arrive in the city on the afternoon of 17th September.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: He will head directly for Narur village, where he will interact with children of a primary school who are being aided by the non-profit organisation “Room to Read.”\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: Later, at DLW campus, the Prime Minister will interact with students of Kashi Vidyapeeth, and children assisted by them.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: On the 18th, at BHU Amphitheatre, the Prime Minister will inaugurate or lay the Foundation Stone for various development projects, cumulatively worth more than Rs. 500 crore.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: Among the projects to be inaugurated are: Integrated Power Development Scheme (IPDS) for Puraani Kashi; and an Atal Incubation Centre at BHU.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: Among the projects for which the Foundation Stone will be laid, is the Regional Ophthalmology Centre at BHU.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: The Prime Minister will also address the gathering.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "\n",
      "--- Doc 2: After Self-Training ---\n",
      "EN: The Prime Minister, Shri Narendra Modi, will launch the Stand Up India initiative at Noida tomorrow.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: The initiative will promote entrepreneurship among the Scheduled Castes, Scheduled Tribes, and Women, by facilitating loans in the range of Rs. 10 Lakhs to Rs. 100 Lakhs.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: Each branch of a scheduled commercial bank shall facilitate at least two such loans.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: A web portal will also be launched for the initiative, to enable online registration and support services.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: The Prime Minister will flag-off 5100 e-rickshaws on the occasion.\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n",
      "EN: He will interact with the beneficiaries, besides inaugurating a Kaushal Vikas Kendra (Skilling Centre).\n",
      "HI: उन्‍होंने कहा ।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "model.load_state_dict(torch.load(\"5c.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "for idx, doc in enumerate(en_test[:2]):\n",
    "    print_translations(model, tokenizer, doc, title=f\"Doc {idx+1}: After Self-Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(en_test):\n",
    "    write_translations(model, tokenizer, doc, hi_test_names[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcsci544",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
